{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfd0f823",
   "metadata": {},
   "source": [
    "# Sen1Floods11 — Step 1: Data Preprocessing (U-Net, 256×256)\n",
    "This notebook builds processed 2-channel (VV,VH) tiles and binary masks, normalizes data, writes manifests, and produces quick sanity plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9d6a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, glob, math, random, shutil, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings('ignore')\n",
    "print('Python:', sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cced6660",
   "metadata": {},
   "source": [
    "## Paths & config\n",
    "Adjust RAW_DIR to your local Sen1Floods11 root. Processed outputs go to processed/images, processed/masks, processed/manifests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b9ac87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project root inferred from this notebook location\n",
    "ROOT = Path.cwd().parent if Path.cwd().name == 'notebooks' else Path.cwd()\n",
    "# Prefer environment variable SEN1FLOODS11_DIR if set; else default under data/\n",
    "RAW_DIR = Path(os.getenv('SEN1FLOODS11_DIR', str(ROOT / 'data' / 'sen1floods11')))\n",
    "PROC_DIR = ROOT / 'processed'\n",
    "IMG_DIR = PROC_DIR / 'images'\n",
    "MSK_DIR = PROC_DIR / 'masks'\n",
    "MAN_DIR = PROC_DIR / 'manifests'\n",
    "for d in [PROC_DIR, IMG_DIR, MSK_DIR, MAN_DIR]: d.mkdir(parents=True, exist_ok=True)\n",
    "TILE_SIZE = 256\n",
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "print('ROOT=', ROOT)\n",
    "print('RAW_DIR=', RAW_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bbdd60",
   "metadata": {},
   "source": [
    "## Install deps (if needed)\n",
    "Uncomment to install rasterio/geopandas/albumentations in notebook env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14104786",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install rasterio geopandas albumentations imageio\n",
    "import rasterio, imageio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b48b9e80",
   "metadata": {},
   "source": [
    "## I/O helpers: read VV/VH stack, mask, normalize, tiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d5f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_vv_vh(vv_path: Path, vh_path: Path):\n",
    "    import rasterio\n",
    "    with rasterio.open(vv_path) as src:\n",
    "        vv = src.read(1).astype('float32')\n",
    "        meta = src.meta.copy()\n",
    "    with rasterio.open(vh_path) as src:\n",
    "        vh = src.read(1).astype('float32')\n",
    "    stack = np.stack([vv, vh], axis=0)  # (2,H,W)\n",
    "    return stack, meta\n",
    "\n",
    "def try_read_mask(mask_path: Path):\n",
    "    # Try raster first; fallback to imageio (PNG)\n",
    "    try:\n",
    "        with rasterio.open(mask_path) as src:\n",
    "            m = src.read(1)\n",
    "            return (m > 0).astype('uint8')\n",
    "    except Exception:\n",
    "        m = imageio.v2.imread(mask_path)\n",
    "        if m.ndim == 3:\n",
    "            m = m[...,0]\n",
    "        return (m > 0).astype('uint8')\n",
    "\n",
    "def normalize_stack(stack, pmin=1, pmax=99):\n",
    "    out = stack.copy()\n",
    "    for i in range(out.shape[0]):\n",
    "        band = out[i]\n",
    "        lo = np.percentile(band[~np.isnan(band)], pmin) if np.any(~np.isnan(band)) else np.nanmin(band)\n",
    "        hi = np.percentile(band[~np.isnan(band)], pmax) if np.any(~np.isnan(band)) else np.nanmax(band)\n",
    "        out[i] = np.clip((band - lo) / (hi - lo + 1e-6), 0, 1)\n",
    "    return out\n",
    "\n",
    "def tile_and_save(stack, mask, meta, base_id: str, out_img_dir: Path, out_mask_dir: Path, tile=256):\n",
    "    H, W = stack.shape[1], stack.shape[2]\n",
    "    tid_list = []\n",
    "    tcount = 0\n",
    "    for y in range(0, H, tile):\n",
    "        for x in range(0, W, tile):\n",
    "            if y+tile > H or x+tile > W:\n",
    "                continue\n",
    "            img_tile = stack[:, y:y+tile, x:x+tile]\n",
    "            mask_tile = mask[y:y+tile, x:x+tile]\n",
    "            # require some valid pixels\n",
    "            valid = np.count_nonzero(~np.isnan(img_tile[0]))\n",
    "            if valid < 0.05 * tile * tile:\n",
    "                continue\n",
    "            img_path = out_img_dir / f'{base_id}_{tcount}.npy'\n",
    "            msk_path = out_mask_dir / f'{base_id}_{tcount}.npy'\n",
    "            np.save(img_path, img_tile)\n",
    "            np.save(msk_path, mask_tile.astype('uint8'))\n",
    "            # Save minimal geo meta per tile (affine shift)\n",
    "            meta_path = out_img_dir / f'{base_id}_{tcount}.json'\n",
    "            tile_meta = {\n",
    "                'transform': list(meta.get('transform', [])) if 'transform' in meta else None,\n",
    "                'crs': str(meta.get('crs', '')) if 'crs' in meta else None,\n",
    "                'x': x, 'y': y, 'tile': tile\n",
    "            }\n",
    "            with open(meta_path, 'w') as f: json.dump(tile_meta, f)\n",
    "            tid_list.append((str(img_path), str(msk_path)))\n",
    "            tcount += 1\n",
    "    return tid_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9493b15",
   "metadata": {},
   "source": [
    "## Discover raw scenes and pair VV/VH/mask\n",
    "Adjust the glob patterns to match your local Sen1Floods11 folder layout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd725269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example patterns (edit to match your structure)\n",
    "VV_GLOB = str(RAW_DIR / '**' / '*VV*.tif')\n",
    "VH_GLOB = str(RAW_DIR / '**' / '*VH*.tif')\n",
    "MSK_GLOB = str(RAW_DIR / '**' / '*mask*.tif')  # or *.png\n",
    "\n",
    "vv_files = sorted(glob.glob(VV_GLOB, recursive=True))\n",
    "vh_files = sorted(glob.glob(VH_GLOB, recursive=True))\n",
    "msk_files = sorted(glob.glob(MSK_GLOB, recursive=True))\n",
    "print('Found', len(vv_files), 'VV,', len(vh_files), 'VH,', len(msk_files), 'masks')\n",
    "\n",
    "# Simple pairing heuristic by basename key (customize if needed)\n",
    "def key(p):\n",
    "    b = Path(p).stem\n",
    "    b = b.replace('VV','').replace('VH','').replace('_mask','')\n",
    "    return b\n",
    "\n",
    "vh_map = {key(p): p for p in vh_files}\n",
    "msk_map = {key(p): p for p in msk_files}\n",
    "pairs = []\n",
    "for v in vv_files:\n",
    "    k = key(v)\n",
    "    if k in vh_map and k in msk_map:\n",
    "        pairs.append((v, vh_map[k], msk_map[k], k))\n",
    "print('Paired scenes:', len(pairs))\n",
    "pairs[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edab3aad",
   "metadata": {},
   "source": [
    "## Process scenes → tiles and manifests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada57824",
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for vv_path, vh_path, msk_path, scene_id in pairs:\n",
    "    try:\n",
    "        stack, meta = read_vv_vh(vv_path, vh_path)\n",
    "        mask = try_read_mask(msk_path)\n",
    "        stack = normalize_stack(stack)\n",
    "        tiles = tile_and_save(stack, mask, meta, base_id=scene_id, out_img_dir=IMG_DIR, out_mask_dir=MSK_DIR, tile=TILE_SIZE)\n",
    "        for img_p, msk_p in tiles:\n",
    "            records.append({\n",
    "                'id': Path(img_p).stem,\n",
    "                'image_path': str(img_p),\n",
    "                'mask_path': str(msk_p),\n",
    "                'scene_id': scene_id\n",
    "            })\n",
    "    except Exception as e:\n",
    "        print('Skip scene due to error:', scene_id, e)\n",
    "\n",
    "df = pd.DataFrame(records)\n",
    "print('Total tiles:', len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10a9d9",
   "metadata": {},
   "source": [
    "## Train/Val split and write manifests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ff3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_df, val_df = train_test_split(df, test_size=0.2, random_state=SEED, stratify=df['scene_id']) if len(df['scene_id'].unique())>1 else (df, df.sample(frac=0))\n",
    "train_csv = MAN_DIR / 'train.csv'\n",
    "val_csv = MAN_DIR / 'val.csv'\n",
    "train_df.to_csv(train_csv, index=False)\n",
    "val_df.to_csv(val_csv, index=False)\n",
    "print('Wrote:', train_csv, 'and', val_csv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f48ad5bb",
   "metadata": {},
   "source": [
    "## Quick sanity check: visualize one tile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be538cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df):\n",
    "    r = df.sample(1).iloc[0]\n",
    "    img = np.load(r['image_path'])  # (2,H,W)\n",
    "    msk = np.load(r['mask_path'])  # (H,W)\n",
    "    fig,axs = plt.subplots(1,3, figsize=(10,4))\n",
    "    axs[0].imshow(img[0], cmap='gray'); axs[0].set_title('VV')\n",
    "    axs[1].imshow(img[1], cmap='gray'); axs[1].set_title('VH')\n",
    "    axs[2].imshow(msk, cmap='Blues'); axs[2].set_title('Mask')\n",
    "    [a.axis('off') for a in axs]; plt.tight_layout(); plt.show()\n",
    "else:\n",
    "    print('No tiles built yet — check RAW_DIR patterns and rerun.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0204e8e",
   "metadata": {},
   "source": [
    "## Next: Training U-Net (Option B, PyTorch)\n",
    "Use the manifests to build DataLoaders with albumentations and train a U-Net (efficientnet-b0 encoder)."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
